{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe201146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\obidur rahman\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\obidur rahman\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\obidur rahman\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.15.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\obidur rahman\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: optuna in c:\\users\\obidur rahman\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\obidur rahman\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\obidur rahman\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\obidur rahman\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\obidur rahman\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\obidur rahman\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\obidur rahman\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from optuna) (1.16.1)\n",
      "Requirement already satisfied: colorlog in c:\\users\\obidur rahman\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\obidur rahman\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from optuna) (24.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in c:\\users\\obidur rahman\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from optuna) (2.0.41)\n",
      "Requirement already satisfied: tqdm in c:\\users\\obidur rahman\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\obidur rahman\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from optuna) (6.0.2)\n",
      "Requirement already satisfied: Mako in c:\\users\\obidur rahman\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in c:\\users\\obidur rahman\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\obidur rahman\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\obidur rahman\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna) (3.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\obidur rahman\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\obidur rahman\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy pandas scipy scikit-learn optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c535d8c",
   "metadata": {},
   "source": [
    "1. Dataset Loading and Preprocessing\n",
    "\n",
    "First, you need to load your .arff datasets and prepare them for scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71e49568",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def load_and_preprocess_arff(filepath, target_column_name=None):\n",
    "    \"\"\"\n",
    "    Loads an ARFF file, identifies features and target, and prepares data.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): Path to the .arff file.\n",
    "        target_column_name (str, optional): Name of the target column.\n",
    "                                            If None, assumes last column is target.\n",
    "\n",
    "    Returns:\n",
    "        tuple: X (features DataFrame), y (target Series), feature_names, categorical_features_idx\n",
    "    \"\"\"\n",
    "    data, meta = arff.loadarff('datasets/covtype-normalized.arff')\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Decode byte strings to standard strings for all columns\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object': # Check if dtype is object, which means it might contain byte strings\n",
    "            try:\n",
    "                # Attempt to decode, if it fails, it might be a different object type or mixed\n",
    "                df[col] = df[col].apply(lambda x: x.decode('utf-8') if isinstance(x, bytes) else x)\n",
    "            except (UnicodeDecodeError, AttributeError):\n",
    "                # Handle cases where not all are bytes or if decoding fails\n",
    "                pass\n",
    "\n",
    "    if target_column_name is None:\n",
    "        target_column_name = df.columns[-1]\n",
    "\n",
    "    X = df.drop(columns=[target_column_name])\n",
    "    y = df[target_column_name]\n",
    "\n",
    "    # Identify categorical and numerical features\n",
    "    categorical_features = X.select_dtypes(include=['object', 'category']).columns\n",
    "    numerical_features = X.select_dtypes(include=np.number).columns\n",
    "\n",
    "    # Get indices for ColumnTransformer\n",
    "    feature_names = X.columns.tolist()\n",
    "    categorical_features_idx = [feature_names.index(col) for col in categorical_features]\n",
    "\n",
    "    print(f\"Loaded {filepath}. Shape: {df.shape}\")\n",
    "    print(f\"Target column: {target_column_name}\")\n",
    "    print(f\"Categorical features: {list(categorical_features)}\")\n",
    "    print(f\"Numerical features: {list(numerical_features)}\")\n",
    "\n",
    "    return X, y, feature_names, categorical_features_idx, df.columns.tolist() # Return all column names too\n",
    "\n",
    "def get_preprocessor(numerical_features, categorical_features):\n",
    "    \"\"\"\n",
    "    Creates a column transformer for preprocessing.\n",
    "    \"\"\"\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', 'passthrough', numerical_features), # No transformation for numerical\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "        ],\n",
    "        remainder='passthrough' # Keep other columns if any, or 'drop' them\n",
    "    )\n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ceeeed",
   "metadata": {},
   "source": [
    "2. Optuna Objective Function (with Partial RF Evaluation)\n",
    "\n",
    "This is the core of your HPO logic for a single trial. It defines how a Random Forest is trained partially and how its performance is reported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74499635",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold # For classification\n",
    "from sklearn.model_selection import KFold # For regression\n",
    "import warnings\n",
    "\n",
    "# Suppress ConvergenceWarning from scikit-learn, which might occur with warm_start\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='sklearn')\n",
    "\n",
    "def objective(trial, X_train_raw, y_train_encoded, X_val_raw, y_val_encoded,\n",
    "              task_type='classification', preprocessor=None, max_n_estimators_upper_bound=1000):\n",
    "    \"\"\"\n",
    "    Optuna objective function for Random Forest HPO with multi-fidelity evaluation.\n",
    "\n",
    "    Args:\n",
    "        trial (optuna.trial.Trial): Current Optuna trial object.\n",
    "        X_train_raw (pd.DataFrame): Raw training features.\n",
    "        y_train_encoded (np.array): Encoded training target.\n",
    "        X_val_raw (pd.DataFrame): Raw validation features.\n",
    "        y_val_encoded (np.array): Encoded validation target.\n",
    "        task_type (str): 'classification' or 'regression'.\n",
    "        preprocessor (ColumnTransformer): Preprocessing pipeline.\n",
    "        max_n_estimators_upper_bound (int): Max possible n_estimators for a full run.\n",
    "                                            Used to define fidelity levels.\n",
    "\n",
    "    Returns:\n",
    "        float: Validation metric for the trial.\n",
    "    \"\"\"\n",
    "    # 1. Hyperparameter Sampling\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, max_n_estimators_upper_bound)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 2, 32)\n",
    "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 20)\n",
    "    max_features_val = trial.suggest_categorical(\"max_features\", ['sqrt', 'log2', 0.5, 0.7, 1.0])\n",
    "\n",
    "    if task_type == 'classification':\n",
    "        # For classification, adjust criterion and potentially class_weight\n",
    "        criterion = trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\"])\n",
    "        class_weight = trial.suggest_categorical(\"class_weight\", [None, \"balanced\"])\n",
    "        model_class = RandomForestClassifier\n",
    "    else: # Regression\n",
    "        criterion = trial.suggest_categorical(\"criterion\", [\"squared_error\", \"absolute_error\"])\n",
    "        class_weight = None # Not applicable for regression\n",
    "        model_class = RandomForestRegressor\n",
    "\n",
    "    # Instantiate the base model once\n",
    "    rf_model = model_class(\n",
    "        n_estimators=1, # Start with 1, warm_start will add more\n",
    "        max_depth=max_depth,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_features=max_features_val,\n",
    "        criterion=criterion,\n",
    "        class_weight=class_weight,\n",
    "        oob_score=True, # Critical for our strategy\n",
    "        random_state=42,\n",
    "        warm_start=True, # Critical for partial evaluation\n",
    "        n_jobs=-1 # Use all available cores\n",
    "    )\n",
    "\n",
    "    # Preprocess data if a preprocessor is provided\n",
    "    if preprocessor:\n",
    "        X_train_processed = preprocessor.fit_transform(X_train_raw)\n",
    "        X_val_processed = preprocessor.transform(X_val_raw)\n",
    "    else:\n",
    "        X_train_processed = X_train_raw\n",
    "        X_val_processed = X_val_raw\n",
    "\n",
    "\n",
    "    # 2. Fidelity Schedule and Partial Evaluation\n",
    "    # Define fidelity steps as a percentage of the suggested n_estimators for this trial\n",
    "    # Using small steps to simulate fine-grained learning curve\n",
    "    fidelity_steps = [int(n_estimators * p) for p in [0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]]\n",
    "    fidelity_steps = sorted(list(set([max(1, s) for s in fidelity_steps]))) # Ensure at least 1 estimator\n",
    "\n",
    "    for step_n_estimators in fidelity_steps:\n",
    "        if step_n_estimators > rf_model.n_estimators: # Only add if more estimators are needed\n",
    "            rf_model.n_estimators = step_n_estimators # Update n_estimators\n",
    "            rf_model.fit(X_train_processed, y_train_encoded) # Incremental fit due to warm_start=True\n",
    "\n",
    "        # Get OOB score - OOB score is available if oob_score=True and n_estimators > 1\n",
    "        # For the very first step (1 estimator), OOB score might not be reliable or available\n",
    "        if rf_model.n_estimators > 1 and hasattr(rf_model, 'oob_score_'):\n",
    "            current_oob_score = rf_model.oob_score_\n",
    "        else:\n",
    "            # Fallback for very early steps or if OOB score isn't directly meaningful yet\n",
    "            # Can use a placeholder or simply avoid reporting for these steps if pruner handles it\n",
    "            current_oob_score = np.nan # Or a base performance\n",
    "\n",
    "        # 3. Report intermediate result to Optuna.\n",
    "        # It's crucial to report the metric that the pruner expects to minimize/maximize.\n",
    "        # For accuracy/AUC, we maximize. For error (RMSE, OOB error), we minimize.\n",
    "        # Let's assume we want to maximize some score. If OOB_score is an error, invert it.\n",
    "        # Here we'll report OOB score directly and let the pruner handle min/max (or convert it)\n",
    "        if task_type == 'classification':\n",
    "            # OOB_score_ for RandomForestClassifier is accuracy. So, maximize.\n",
    "            trial.report(current_oob_score, step=step_n_estimators)\n",
    "        else:\n",
    "            # OOB_score_ for RandomForestRegressor is R^2. So, maximize.\n",
    "            trial.report(current_oob_score, step=step_n_estimators)\n",
    "\n",
    "\n",
    "        # 4. Check for pruning. The CustomPruner will receive this report.\n",
    "        if trial.should_prune():\n",
    "            print(f\"Trial {trial.number} pruned at {step_n_estimators} estimators (OOB: {current_oob_score:.4f}).\")\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    # Final evaluation on validation set after full training\n",
    "    y_pred = rf_model.predict(X_val_processed)\n",
    "\n",
    "    if task_type == 'classification':\n",
    "        # For binary classification, use predict_proba for AUC\n",
    "        if hasattr(rf_model, 'predict_proba') and len(np.unique(y_val_encoded)) == 2:\n",
    "            y_proba = rf_model.predict_proba(X_val_processed)[:, 1]\n",
    "            final_metric = roc_auc_score(y_val_encoded, y_proba)\n",
    "            metric_name = \"AUC\"\n",
    "        else: # Multi-class or if proba not available\n",
    "            final_metric = accuracy_score(y_val_encoded, y_pred)\n",
    "            metric_name = \"Accuracy\"\n",
    "    else: # Regression\n",
    "        final_metric = -mean_squared_error(y_val_encoded, y_pred) # Minimize MSE, so negate for Optuna (maximize)\n",
    "        metric_name = \"Negative MSE\"\n",
    "\n",
    "    print(f\"Trial {trial.number} completed with {metric_name}: {final_metric:.4f}\")\n",
    "    return final_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0e8cc1",
   "metadata": {},
   "source": [
    "3. Custom Optuna Pruner Implementation\n",
    "\n",
    "This is where your \"Performance Prediction from Partial Evaluation\" and \"Pruning Logic\" come together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25e186b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sklearn.linear_model import LinearRegression # Simple model for illustration\n",
    "\n",
    "class RandomForestMultiFidelityPruner(optuna.pruners.BasePruner):\n",
    "    \"\"\"\n",
    "    Custom Optuna pruner for Random Forest Hyperparameter Optimization\n",
    "    using a multi-fidelity approach and learning curve prediction.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 min_intermediate_steps=5, # Minimum number of reported steps before considering pruning\n",
    "                 pruning_quantile=0.25,     # Prune if predicted performance is below this quantile of best\n",
    "                 grace_period_ratio=0.1,    # Proportion of n_estimators_max to wait before aggressive pruning\n",
    "                 predictive_model_type='linear'): # 'linear' or 'simple_extrapolation'\n",
    "        self.min_intermediate_steps = min_intermediate_steps\n",
    "        self.pruning_quantile = pruning_quantile\n",
    "        self.grace_period_ratio = grace_period_ratio\n",
    "        self.predictive_model_type = predictive_model_type\n",
    "\n",
    "        # Store historical OOB scores and steps for performance prediction model\n",
    "        # Structure: {trial_id: [(step1, oob_score1), (step2, oob_score2), ...]}\n",
    "        self.trial_learning_curves = defaultdict(list)\n",
    "        self.completed_trial_performances = [] # Store final performances of completed trials\n",
    "\n",
    "    def prune(self, study: optuna.study.Study, trial: optuna.trial.FrozenTrial) -> bool:\n",
    "        trial_id = trial.number\n",
    "        current_step = trial.last_step\n",
    "        current_value = trial.value\n",
    "\n",
    "        # Store current intermediate value for learning curve\n",
    "        if current_step is not None and current_value is not None:\n",
    "            self.trial_learning_curves[trial_id].append((current_step, current_value))\n",
    "\n",
    "        # Do not prune during the grace period or if too few steps have been reported\n",
    "        if current_step < self.grace_period_ratio * trial.params.get('n_estimators', 1000) or \\\n",
    "           len(self.trial_learning_curves[trial_id]) < self.min_intermediate_steps:\n",
    "            return False\n",
    "\n",
    "        # Get historical data for the current trial's learning curve\n",
    "        current_lc_data = self.trial_learning_curves[trial_id]\n",
    "        steps = np.array([s for s, _ in current_lc_data])\n",
    "        values = np.array([v for _, v in current_lc_data])\n",
    "        \n",
    "        # Ensure we have enough data points to fit a predictor\n",
    "        if len(steps) < 2: # Need at least 2 points for a simple line or curve\n",
    "            return False\n",
    "\n",
    "        # Predict final performance based on partial evaluation\n",
    "        predicted_final_performance = self._predict_final_performance(steps, values, trial.params.get('n_estimators', 1000))\n",
    "\n",
    "        # Get best completed trial's performance so far\n",
    "        # Optuna stores objective values. We need to handle maximization vs minimization.\n",
    "        # By default, Optuna aims to minimize. If our objective returns a higher-is-better metric,\n",
    "        # we need to consider 'study.best_value' carefully.\n",
    "        # Assuming our objective returns a higher-is-better metric (e.g., AUC, Accuracy),\n",
    "        # so study.best_value is the max.\n",
    "        best_objective_value = study.best_value\n",
    "\n",
    "        # Only prune if there are completed trials to compare against\n",
    "        if best_objective_value is None:\n",
    "            return False\n",
    "\n",
    "        # Pruning logic: Compare predicted performance to a quantile of best so far\n",
    "        # We need to compute a threshold based on the distribution of past performances,\n",
    "        # or relative to the best_objective_value.\n",
    "        # For maximization: Prune if predicted_final_performance is significantly worse than best_objective_value.\n",
    "        \n",
    "        # A simple approach: prune if predicted performance is X% worse than the best.\n",
    "        # Or, if predicted performance is below a certain quantile of *all completed trials' final performances*.\n",
    "        \n",
    "        # For this example, let's use a simpler heuristic:\n",
    "        # Prune if predicted performance is below the (pruning_quantile) quantile of the best\n",
    "        # of completed trials' final performances.\n",
    "        \n",
    "        # NOTE: This pruner needs to be \"aware\" if Optuna is maximizing or minimizing.\n",
    "        # For maximization (like AUC or Accuracy), a lower value is worse.\n",
    "        # For minimization (like OOB error directly, or MSE), a higher value is worse.\n",
    "        # Assume our objective always returns a metric that Optuna maximizes (e.g., -MSE or Accuracy)\n",
    "        \n",
    "        # To get the best completed trials, we iterate and filter\n",
    "        completed_trial_values = [\n",
    "            t.value for t in study.trials\n",
    "            if t.state == optuna.trial.TrialState.COMPLETE and t.value is not None\n",
    "        ]\n",
    "        \n",
    "        if not completed_trial_values:\n",
    "            return False # No completed trials to compare against yet\n",
    "\n",
    "        # This part requires careful thought:\n",
    "        # If maximizing, we want to prune trials whose P_pred is \"too low\".\n",
    "        # If minimizing, we want to prune trials whose P_pred is \"too high\".\n",
    "        # Optuna's best_value is always \"best\" according to its direction.\n",
    "        \n",
    "        # Let's assume the objective always returns a metric to be maximized (e.g., Accuracy, AUC, negative MSE).\n",
    "        # So, lower values are worse.\n",
    "        threshold = np.quantile(completed_trial_values, self.pruning_quantile) # e.g., 25th percentile of completed trials\n",
    "        \n",
    "        # Apply a safety margin for the uncertainty trap, especially if few trials are complete\n",
    "        # This margin could be dynamic, e.g., wider if standard deviation of values is high\n",
    "        safety_margin = 0.0 # Placeholder for more sophisticated margin logic\n",
    "        \n",
    "        # If predicted_final_performance is worse than the threshold, prune.\n",
    "        if predicted_final_performance < (threshold - safety_margin):\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "\n",
    "    def _predict_final_performance(self, steps, values, max_n_estimators):\n",
    "        \"\"\"\n",
    "        Predicts the final performance based on observed learning curve.\n",
    "        \"\"\"\n",
    "        if self.predictive_model_type == 'linear':\n",
    "            # Simple linear regression on steps vs values\n",
    "            # This is a very basic model and might not capture RF learning curve well\n",
    "            model = LinearRegression()\n",
    "            model.fit(steps.reshape(-1, 1), values)\n",
    "            predicted_value = model.predict(np.array([[max_n_estimators]]))[0]\n",
    "            \n",
    "            # Simple heuristic: If prediction goes beyond observed range in a \"bad\" direction, cap it.\n",
    "            # For maximization: predicted_value should not be lower than min observed, nor higher than max observed by much\n",
    "            # For minimization: predicted_value should not be higher than max observed, nor lower than min observed by much\n",
    "            if max_n_estimators > steps[-1]: # If extrapolating\n",
    "                # If maximizing, ensure prediction doesn't sharply decline\n",
    "                if predicted_value < values[-1] and (values[-1] - predicted_value) > np.std(values):\n",
    "                    predicted_value = values[-1] # Cap it to last observed value if it's a sharp decline\n",
    "\n",
    "            return predicted_value\n",
    "\n",
    "        elif self.predictive_model_type == 'simple_extrapolation':\n",
    "            # Assumes performance plateaus or improves slowly after a certain point.\n",
    "            # Averages last few observations to predict final.\n",
    "            if len(values) >= 3: # Need at least last 3 points for averaging\n",
    "                return np.mean(values[-3:])\n",
    "            else:\n",
    "                return values[-1] # Fallback to last observed value\n",
    "\n",
    "        # You would implement more complex models here, e.g., curve fitting for exponential decay/saturation\n",
    "        # For RF OOB, a common pattern is to fit an exponential decay or similar saturation curve.\n",
    "        # Example for curve fitting (requires scipy.optimize.curve_fit):\n",
    "        # from scipy.optimize import curve_fit\n",
    "        # def learning_curve_func(x, a, b, c): # e.g., a * exp(-b*x) + c for minimization\n",
    "        #     return a * np.exp(-b * x) + c\n",
    "        # try:\n",
    "        #     popt, pcov = curve_fit(learning_curve_func, steps, values, p0=[1, 0.1, np.mean(values)])\n",
    "        #     return learning_curve_func(max_n_estimators, *popt)\n",
    "        # except RuntimeError:\n",
    "        #     return values[-1] # Fallback if curve_fit fails\n",
    "\n",
    "        return values[-1] # Default fallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97eae981",
   "metadata": {},
   "source": [
    "4. Running the Optuna Study\n",
    "\n",
    "This brings all the pieces together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d998b6a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Rings'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     10\u001b[39m TASK_TYPE = \u001b[33m'\u001b[39m\u001b[33mregression\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;66;03m# 'classification' or 'regression'\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# --- Load and Preprocess Data ---\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Load the raw data (replace with your actual file loading)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m X_raw, y_raw, feature_names, categorical_features_idx, all_cols = \u001b[43mload_and_preprocess_arff\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mDATASET_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_column_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTARGET_COLUMN\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Encode target variable if classification and not already numeric\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TASK_TYPE == \u001b[33m'\u001b[39m\u001b[33mclassification\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (y_raw.dtype == \u001b[33m'\u001b[39m\u001b[33mobject\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y_raw.dtype == \u001b[33m'\u001b[39m\u001b[33mcategory\u001b[39m\u001b[33m'\u001b[39m):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mload_and_preprocess_arff\u001b[39m\u001b[34m(filepath, target_column_name)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m target_column_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     35\u001b[39m     target_column_name = df.columns[-\u001b[32m1\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m X = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarget_column_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m y = df[target_column_name]\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Identify categorical and numerical features\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Obidur Rahman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:5581\u001b[39m, in \u001b[36mDataFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   5433\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdrop\u001b[39m(\n\u001b[32m   5434\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   5435\u001b[39m     labels: IndexLabel | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5442\u001b[39m     errors: IgnoreRaise = \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   5443\u001b[39m ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5444\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5445\u001b[39m \u001b[33;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[32m   5446\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5579\u001b[39m \u001b[33;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[32m   5580\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5581\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5582\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5583\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5584\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5585\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5586\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5587\u001b[39m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5588\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5589\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Obidur Rahman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:4788\u001b[39m, in \u001b[36mNDFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   4786\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes.items():\n\u001b[32m   4787\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4788\u001b[39m         obj = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4790\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[32m   4791\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_inplace(obj)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Obidur Rahman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:4830\u001b[39m, in \u001b[36mNDFrame._drop_axis\u001b[39m\u001b[34m(self, labels, axis, level, errors, only_slice)\u001b[39m\n\u001b[32m   4828\u001b[39m         new_axis = axis.drop(labels, level=level, errors=errors)\n\u001b[32m   4829\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4830\u001b[39m         new_axis = \u001b[43maxis\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4831\u001b[39m     indexer = axis.get_indexer(new_axis)\n\u001b[32m   4833\u001b[39m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[32m   4834\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Obidur Rahman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7070\u001b[39m, in \u001b[36mIndex.drop\u001b[39m\u001b[34m(self, labels, errors)\u001b[39m\n\u001b[32m   7068\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mask.any():\n\u001b[32m   7069\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors != \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m7070\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask].tolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found in axis\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   7071\u001b[39m     indexer = indexer[~mask]\n\u001b[32m   7072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.delete(indexer)\n",
      "\u001b[31mKeyError\u001b[39m: \"['Rings'] not found in axis\""
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold # Import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import functools # For partial function application\n",
    "\n",
    "# --- Configuration Parameters ---\n",
    "N_TRIALS = 100 # Number of HPO trials\n",
    "RANDOM_STATE = 42\n",
    "DATASET_PATH = 'your_dataset.arff' # Update this\n",
    "TARGET_COLUMN = 'Rings' # Update this for your dataset\n",
    "TASK_TYPE = 'regression' # 'classification' or 'regression'\n",
    "\n",
    "# --- Load and Preprocess Data ---\n",
    "# Load the raw data (replace with your actual file loading)\n",
    "X_raw, y_raw, feature_names, categorical_features_idx, all_cols = load_and_preprocess_arff(\n",
    "    DATASET_PATH, target_column_name=TARGET_COLUMN\n",
    ")\n",
    "\n",
    "# Encode target variable if classification and not already numeric\n",
    "if TASK_TYPE == 'classification' and (y_raw.dtype == 'object' or y_raw.dtype == 'category'):\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y_raw)\n",
    "    print(f\"Encoded target classes: {le.classes_}\")\n",
    "else:\n",
    "    y_encoded = y_raw\n",
    "\n",
    "# Create the preprocessor\n",
    "numerical_feats = X_raw.select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_feats = X_raw.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "data_preprocessor = get_preprocessor(numerical_feats, categorical_feats)\n",
    "\n",
    "# Split into training and validation sets for the objective function\n",
    "# Note: For robust evaluation in a full research paper, you'd typically use K-Fold Cross-Validation\n",
    "# outside the Optuna study, and Optuna's objective would run on internal validation sets\n",
    "# or average K-Fold results. For a single train/val split for quick demonstration:\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "    X_raw, y_encoded, test_size=0.2, random_state=RANDOM_STATE,\n",
    "    stratify=y_encoded if TASK_TYPE == 'classification' else None\n",
    ")\n",
    "\n",
    "\n",
    "# --- Initialize Custom Pruner ---\n",
    "custom_pruner = RandomForestMultiFidelityPruner(\n",
    "    min_intermediate_steps=5,\n",
    "    pruning_quantile=0.25, # Prune if predicted performance is in the bottom 25% of completed trials\n",
    "    grace_period_ratio=0.1, # Don't prune for first 10% of n_estimators\n",
    "    predictive_model_type='linear' # or 'simple_extrapolation'\n",
    ")\n",
    "\n",
    "# --- Create Optuna Study ---\n",
    "# Set direction to 'maximize' if your objective returns Accuracy, AUC, or -MSE (higher is better)\n",
    "# Set direction to 'minimize' if your objective returns Error (e.g., OOB_error or MSE directly, lower is better)\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\" if TASK_TYPE == 'classification' else \"maximize\", # Assuming we maximize accuracy/AUC or -MSE\n",
    "    pruner=custom_pruner,\n",
    "    sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE),\n",
    "    study_name=\"rf_multi_fidelity_hpo_study\",\n",
    "    storage=\"sqlite:///rf_hpo.db\" # Optional: Persist study results to a DB\n",
    ")\n",
    "\n",
    "# --- Wrap the objective function with fixed arguments ---\n",
    "# Using functools.partial to pass fixed arguments to the objective\n",
    "objective_with_args = functools.partial(\n",
    "    objective,\n",
    "    X_train_raw=X_train_split,\n",
    "    y_train_encoded=y_train_split,\n",
    "    X_val_raw=X_val_split,\n",
    "    y_val_encoded=y_val_split,\n",
    "    task_type=TASK_TYPE,\n",
    "    preprocessor=data_preprocessor,\n",
    "    max_n_estimators_upper_bound=1000 # Example, make sure this matches your search space's upper bound\n",
    ")\n",
    "\n",
    "# --- Start the Optimization ---\n",
    "print(f\"Starting Optuna study with {N_TRIALS} trials...\")\n",
    "study.optimize(objective_with_args, n_trials=N_TRIALS, show_progress_bar=True)\n",
    "\n",
    "# --- Print Results ---\n",
    "print(\"\\nOptimization finished.\")\n",
    "print(f\"Best trial: {study.best_trial.value:.4f}\")\n",
    "print(\"Best hyperparameters:\")\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# You can also access trial details\n",
    "pruned_trials = study.get_trials(deepcopy=False, states=[optuna.trial.TrialState.PRUNED])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[optuna.trial.TrialState.COMPLETE])\n",
    "print(f\"Number of pruned trials: {len(pruned_trials)}\")\n",
    "print(f\"Number of complete trials: {len(complete_trials)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edc9d09",
   "metadata": {},
   "source": [
    "5. Evaluation and Results Saving\n",
    "\n",
    "After the study, you'll want to save and analyze your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead480fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib # For saving models and preprocessors\n",
    "import time\n",
    "\n",
    "def evaluate_final_model(best_params, X_train_full, y_train_full, X_test_full, y_test_full,\n",
    "                         task_type='classification', preprocessor=None):\n",
    "    \"\"\"\n",
    "    Trains the best model from HPO on the full training data and evaluates on a test set.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Preprocess full data\n",
    "    if preprocessor:\n",
    "        X_train_processed = preprocessor.fit_transform(X_train_full)\n",
    "        X_test_processed = preprocessor.transform(X_test_full)\n",
    "    else:\n",
    "        X_train_processed = X_train_full\n",
    "        X_test_processed = X_test_full\n",
    "\n",
    "    # Re-instantiate the best model\n",
    "    if task_type == 'classification':\n",
    "        model = RandomForestClassifier(random_state=42, n_jobs=-1, **best_params)\n",
    "    else:\n",
    "        model = RandomForestRegressor(random_state=42, n_jobs=-1, **best_params)\n",
    "\n",
    "    model.fit(X_train_processed, y_train_full)\n",
    "    fit_time = time.time() - start_time\n",
    "\n",
    "    # Evaluate\n",
    "    y_pred = model.predict(X_test_processed)\n",
    "\n",
    "    if task_type == 'classification':\n",
    "        final_metric = accuracy_score(y_test_full, y_pred)\n",
    "        metric_name = \"Accuracy\"\n",
    "        if hasattr(model, 'predict_proba') and len(np.unique(y_test_full)) == 2:\n",
    "            y_proba = model.predict_proba(X_test_processed)[:, 1]\n",
    "            auc_score = roc_auc_score(y_test_full, y_proba)\n",
    "            print(f\"Final Model AUC: {auc_score:.4f}\")\n",
    "    else:\n",
    "        final_metric = mean_squared_error(y_test_full, y_pred)\n",
    "        metric_name = \"MSE\"\n",
    "\n",
    "    print(f\"\\n--- Final Model Evaluation ---\")\n",
    "    print(f\"Metric ({metric_name}): {final_metric:.4f}\")\n",
    "    print(f\"Training time for final model: {fit_time:.2f} seconds\")\n",
    "\n",
    "    return model, final_metric\n",
    "\n",
    "\n",
    "# --- Example of full training and evaluation ---\n",
    "# Assuming you have loaded X_raw, y_encoded, data_preprocessor from before\n",
    "\n",
    "# Final split for evaluation\n",
    "X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(\n",
    "    X_raw, y_encoded, test_size=0.2, random_state=RANDOM_STATE,\n",
    "    stratify=y_encoded if TASK_TYPE == 'classification' else None\n",
    ")\n",
    "\n",
    "if study.best_trial:\n",
    "    best_params = study.best_trial.params\n",
    "    final_model, final_score = evaluate_final_model(\n",
    "        best_params, X_train_full, y_train_full, X_test_full, y_test_full,\n",
    "        task_type=TASK_TYPE, preprocessor=data_preprocessor\n",
    "    )\n",
    "\n",
    "    # Save the best model and preprocessor\n",
    "    joblib.dump(final_model, 'best_rf_model.pkl')\n",
    "    joblib.dump(data_preprocessor, 'data_preprocessor.pkl')\n",
    "    print(\"Best model and preprocessor saved.\")\n",
    "\n",
    "# --- Analysis of Optuna Study Results ---\n",
    "# You can use Optuna's visualization tools\n",
    "# import optuna.visualization as ov\n",
    "# # Requires plotly and kaleido\n",
    "# # pip install plotly kaleido\n",
    "\n",
    "# # Plot optimization history\n",
    "# fig1 = ov.plot_optimization_history(study)\n",
    "# fig1.show()\n",
    "# # Save the plot\n",
    "# # fig1.write_image(\"optimization_history.png\")\n",
    "\n",
    "# # Plot intermediate values\n",
    "# fig2 = ov.plot_intermediate_values(study)\n",
    "# fig2.show()\n",
    "# # fig2.write_image(\"intermediate_values.png\")\n",
    "\n",
    "# # Plot parameter importance\n",
    "# fig3 = ov.plot_param_importances(study)\n",
    "# fig3.show()\n",
    "# # fig3.write_image(\"param_importances.png\")\n",
    "\n",
    "# You can also manually extract data for custom plots (e.g., speedup vs. accuracy from Table 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc62e28a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
